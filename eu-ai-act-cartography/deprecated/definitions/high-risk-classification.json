{
  "id": "high-risk-classification",
  "title": "High-Risk AI System Classification",
  "article": "Article 6",
  "type": "classification_determination",
  "foundational": true,
  "critical_importance": "Determines applicability of ALL Chapter III Section 2 requirements (Art 8-15) and provider obligations (Art 16-29)",
  "confidence_overall": "HIGH",

  "classification_logic": {
    "description": "An AI system is high-risk if it falls under EITHER pathway",
    "operator": "OR",
    "pathways": [
      {
        "id": "pathway_6_1_product_safety",
        "article": "6(1)",
        "title": "Product safety pathway - Annex I harmonisation legislation",
        "operator": "AND",
        "cumulative_conditions": [
          {
            "id": "condition_6_1_a",
            "text": "AI system is intended to be used as safety component of a product OR AI system is itself a product, covered by Union harmonisation legislation listed in Annex I",
            "operator": "OR_WITHIN",
            "sub_conditions": [
              {
                "condition": "AI system intended as safety component of product",
                "reference": "Safety component (3(14))",
                "confidence": "HIGH",
                "note": "AI fulfills safety function or failure endangers health/safety"
              },
              {
                "condition": "AI system is itself a product",
                "confidence": "HIGH",
                "note": "Standalone AI product, not component"
              }
            ],
            "additional_requirement": "Product covered by Union harmonisation legislation in Annex I",
            "confidence": "HIGH",
            "dependency": "Must read Annex I"
          },
          {
            "id": "condition_6_1_b",
            "text": "Product (whose safety component is the AI, or AI as product itself) is required to undergo third-party conformity assessment pursuant to Union harmonisation legislation in Annex I",
            "confidence": "HIGH",
            "critical_element": "Third-party conformity assessment requirement",
            "note": "Not all products in Annex I require third-party assessment - only subset",
            "dependency": "Must check specific harmonisation legislation requirements"
          }
        ],
        "legal_effect": "If both 6(1)(a) AND 6(1)(b) satisfied → AI system IS high-risk",
        "irrespective_of": "Whether placed on market/put into service independently of product",
        "confidence": "HIGH",
        "examples": "Medical device AI, automotive safety AI, aviation safety systems",
        "note": "This pathway ties AI Act compliance to existing product safety regimes"
      },
      {
        "id": "pathway_6_2_annex_iii",
        "article": "6(2)",
        "title": "Annex III use cases pathway",
        "text": "In addition to high-risk systems per 6(1), AI systems referred to in Annex III shall be considered to be high-risk",
        "baseline_rule": "If system falls within Annex III use cases → presumptively high-risk",
        "confidence": "HIGH",
        "dependency": "Must read Annex III comprehensively",
        "subject_to": "Article 6(3) derogation (opt-out mechanism)",
        "note": "This is the main pathway for non-product-safety high-risk systems"
      }
    ]
  },

  "article_6_3_derogation": {
    "id": "derogation_6_3",
    "article": "6(3)",
    "title": "Opt-out from high-risk classification for Annex III systems",
    "description": "Exception allowing provider to classify Annex III system as NOT high-risk",
    "applies_only_to": "Pathway 6(2) - Annex III systems ONLY, NOT pathway 6(1) product safety systems",
    "confidence": "HIGH",

    "threshold_test": {
      "description": "Annex III system NOT high-risk if it meets threshold test",
      "text": "System does not pose a significant risk of harm to health, safety or fundamental rights, including by not materially influencing the outcome of decision making",
      "operator": "AND",
      "cumulative_requirements": [
        {
          "element": "Does not pose significant risk of harm",
          "targets": ["health", "safety", "fundamental rights"],
          "operator": "OR_TARGETS",
          "confidence": "LOW",
          "flag": "LOW_CONFIDENCE: 'significant risk' undefined - requires contextual evaluation",
          "llm_evaluation_needed": true
        },
        {
          "element": "Including by not materially influencing outcome of decision making",
          "confidence": "LOW",
          "flag": "LOW_CONFIDENCE: 'materially influencing' - threshold unclear",
          "llm_evaluation_needed": true,
          "note": "Non-material influence = not high-risk"
        }
      ]
    },

    "alternative_conditions": {
      "description": "Threshold test is met if ANY of these four conditions fulfilled",
      "operator": "OR",
      "article": "6(3) first subparagraph",
      "conditions": [
        {
          "id": "condition_6_3_a",
          "text": "AI system intended to perform a narrow procedural task",
          "confidence": "MEDIUM",
          "flag": "MEDIUM_CONFIDENCE: 'narrow procedural task' - scope unclear",
          "llm_evaluation_needed": true,
          "examples_hypothetical": "Simple data sorting, basic formatting"
        },
        {
          "id": "condition_6_3_b",
          "text": "AI system intended to improve the result of a previously completed human activity",
          "confidence": "MEDIUM",
          "flag": "MEDIUM_CONFIDENCE: What constitutes 'improve'? Post-hoc analysis only?",
          "llm_evaluation_needed": true,
          "note": "Human activity PREVIOUSLY completed - retrospective improvement"
        },
        {
          "id": "condition_6_3_c",
          "text": "AI system intended to detect decision-making patterns or deviations from prior decision-making patterns and is not meant to replace or influence the previously completed human assessment, without proper human review",
          "confidence": "MEDIUM",
          "cumulative_sub_elements": [
            "Detects patterns or deviations",
            "NOT meant to replace or influence prior human assessment",
            "Without proper human review"
          ],
          "flag": "MEDIUM_CONFIDENCE: 'proper human review' undefined",
          "note": "Pattern detection only, no influence on decisions"
        },
        {
          "id": "condition_6_3_d",
          "text": "AI system intended to perform a preparatory task to an assessment relevant for the purposes of the use cases listed in Annex III",
          "confidence": "MEDIUM-HIGH",
          "flag": "MEDIUM_CONFIDENCE: 'preparatory task' - scope unclear",
          "examples_hypothetical": "Data gathering, preliminary sorting before human assessment"
        }
      ],
      "note": "These conditions are illustrative of systems that don't materially influence outcomes"
    },

    "profiling_carve_out": {
      "article": "6(3) second subparagraph",
      "text": "Notwithstanding the first subparagraph, an AI system referred to in Annex III shall ALWAYS be considered to be high-risk where the AI system performs profiling of natural persons",
      "operator": "OVERRIDE",
      "description": "If system profiles natural persons → ALWAYS high-risk, even if 6(3)(a)-(d) conditions met",
      "reference": "Profiling (3(52))",
      "confidence": "HIGH",
      "critical_note": "Profiling = automatic high-risk determination, no opt-out possible",
      "policy_rationale": "Profiling always poses sufficient risk to warrant high-risk classification"
    },

    "provider_obligations_for_opt_out": {
      "article": "6(4)",
      "requirements": [
        {
          "obligation": "Document assessment",
          "timing": "Before system placed on market or put into service",
          "confidence": "HIGH"
        },
        {
          "obligation": "Registration per Article 49(2)",
          "mandatory": true,
          "confidence": "HIGH",
          "note": "Even if opting out of high-risk, must register"
        },
        {
          "obligation": "Provide documentation upon request",
          "to": "National competent authorities",
          "confidence": "HIGH"
        }
      ],
      "critical_note": "Provider bears burden of proof - must document why NOT high-risk"
    }
  },

  "article_6_5_8_guidance_and_amendments": {
    "article_6_5": {
      "text": "Commission shall provide guidelines by 2 Feb 2026 on practical implementation with examples of high-risk and not high-risk use cases",
      "confidence": "HIGH",
      "note": "Future interpretative guidance expected"
    },
    "article_6_6_7": {
      "text": "Commission empowered to adopt delegated acts to amend Article 6(3) conditions",
      "can_add_modify": "New opt-out conditions or modify existing (Art 6(6))",
      "can_delete": "Delete opt-out conditions if necessary for protection (Art 6(7))",
      "constraint": "Cannot decrease overall protection level (Art 6(8))",
      "confidence": "HIGH",
      "note": "Dynamic adjustment mechanism based on evidence"
    }
  },

  "article_7_annex_iii_amendments": {
    "article": "7",
    "title": "Amendments to Annex III",
    "description": "Commission can add, modify, or remove use cases from Annex III",

    "adding_use_cases": {
      "article": "7(1)",
      "operator": "AND",
      "conditions": [
        {
          "id": "condition_7_1_a",
          "text": "AI systems intended to be used in any of the areas listed in Annex III",
          "confidence": "HIGH",
          "note": "Must be in existing Annex III areas - can't add entirely new areas"
        },
        {
          "id": "condition_7_1_b",
          "text": "AI systems pose risk of harm to health/safety OR adverse impact on fundamental rights, equivalent to or greater than existing Annex III high-risk systems",
          "confidence": "MEDIUM",
          "operator": "OR",
          "comparative_test": "Risk ≥ current Annex III risks",
          "assessment_criteria": "Article 7(2) criteria"
        }
      ]
    },

    "assessment_criteria_7_2": {
      "article": "7(2)",
      "description": "Criteria for assessing risk equivalence when amending Annex III",
      "criteria": [
        {"id": "a", "criterion": "Intended purpose of AI system", "confidence": "HIGH"},
        {"id": "b", "criterion": "Extent system has been/likely to be used", "confidence": "HIGH"},
        {"id": "c", "criterion": "Nature and amount of data processed, especially special categories", "confidence": "HIGH"},
        {"id": "d", "criterion": "Extent system acts autonomously and possibility for human override", "confidence": "MEDIUM"},
        {"id": "e", "criterion": "Extent system has caused harm or adverse impact (evidence-based)", "confidence": "HIGH"},
        {"id": "f", "criterion": "Potential extent of harm - intensity and ability to affect multiple/vulnerable persons", "confidence": "MEDIUM"},
        {"id": "g", "criterion": "Extent persons dependent on outcome (cannot opt-out)", "confidence": "MEDIUM"},
        {"id": "h", "criterion": "Extent of power imbalance or vulnerability of affected persons", "confidence": "MEDIUM"},
        {"id": "i", "criterion": "Extent outcome is easily corrigible or reversible", "confidence": "MEDIUM"},
        {"id": "j", "criterion": "Magnitude and likelihood of benefit for individuals/society", "confidence": "MEDIUM"},
        {"id": "k_i", "criterion": "Effective measures of redress (excluding damages)", "confidence": "MEDIUM"},
        {"id": "k_ii", "criterion": "Effective measures to prevent or minimize risks", "confidence": "MEDIUM"}
      ],
      "note": "Comprehensive risk assessment framework - Commission must consider all criteria",
      "confidence_overall": "HIGH on framework, MEDIUM on many individual criteria requiring judgment"
    },

    "removing_use_cases": {
      "article": "7(3)",
      "operator": "AND",
      "conditions": [
        {
          "condition": "System no longer poses significant risks to fundamental rights, health, safety (per Art 7(2) criteria)",
          "confidence": "MEDIUM"
        },
        {
          "condition": "Deletion does not decrease overall protection level under Union law",
          "confidence": "HIGH",
          "constraint": "Cannot lower protection floor"
        }
      ]
    }
  },

  "synthesis": {
    "two_pathways_to_high_risk": [
      "Article 6(1) - Product safety (Annex I) - NO opt-out",
      "Article 6(2) - Use cases (Annex III) - opt-out possible per 6(3) UNLESS profiling"
    ],
    "burden_of_proof": "Provider claiming 6(3) opt-out must document assessment",
    "profiling_rule": "Profiling = always high-risk, no exceptions",
    "dynamic_system": "Commission can amend Annex III and Article 6(3) conditions via delegated acts",
    "guidance_coming": "Commission guidelines by Feb 2026",
    "critical_dependencies": [
      "Annex I (product safety legislation)",
      "Annex III (high-risk use cases) - MUST BE MAPPED FULLY",
      "Article 49(2) (registration for opt-out)"
    ]
  },

  "interpretative_challenges": [
    "Significant risk of harm - threshold undefined",
    "Materially influencing outcome - degree unclear",
    "Narrow procedural task - scope unclear",
    "Preparatory task - boundary with substantive tasks",
    "Proper human review - what constitutes 'proper'",
    "Many Article 7(2) criteria require contextual judgment"
  ],

  "metadata": {
    "foundational": true,
    "shared_node": true,
    "used_by": "ALL Chapter III provisions, Articles 28-29, Article 49",
    "created": "2025-10-08",
    "status": "complete pending Annex I and III mapping",
    "confidence_overall": "HIGH on structure, MEDIUM on interpretative elements"
  }
}
